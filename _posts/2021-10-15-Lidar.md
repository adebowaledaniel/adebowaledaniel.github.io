---
title: "Lidar Classification - CloudCompare"
date: 2021-10-16
excerpt: "Point Cloud classification. <br/><img src='/images/Q.png'/>"
permalink: /posts/2021/10/Lidar/
tags:
  - UBS
  - Active and Passive Remote Sensing
---

Overview
===
The objective of this exercise is to perform an advanced operation in [CloudCompare](https://www.danielgm.net/cc/), a 3D point cloud and mesh processing software
open source software; the goal here is to perform a binary semantic classification using multiscale dimensionality.  

Study Area and Data
===
The area of interest is Queens Towns, New Zealand; the choice of the AOI was base on data availability.   
<img src="/images/Study-Area.png" alt="Study Area" style="height: 300px; width:500px;"/>  
Queenstowns, New Zealand.

The point cloud data (Queenstown 2016) used is obtain from the OpenTopography; the data and its description can be openly accessed [here](https://portal.opentopography.org/lidarDataset?opentopoID=OTLAS.012019.2193.1). The point cloud data already came with two classification, Ground(Brown) and Unclassified(Yellow) as seen in the figure below. A closer observation of the unclassified shows that it includes vegetation and infrastructure (for example, building and Bridge); therefore in this exercises a binary semantic classification for vegetation and buildings is executed using the CANUPO plugin in CloudCompare.  
<img src="/images/qclass.png" alt="Study Area" style="height: 300px; width:500px;"/>  

Methodolody
====
To achieve the goal of this exercise, the *Unclassified* was separated from the *Ground* using the **Classification Scalar Values**.  

<img src="/images/unclassified.png" alt="Study Area" style="height: 300px; width:500px;"/>  

**Train Sample Selection**  
Asforementioned, this binary classifcation is aimed further semantically separate the unclassified into Vegetation and Buildings. The sample selection process is very cruicial as it involve logical selection of point cloud with respect to their semantic representation in 3D of the two target classes. One of the precautions taken was to aviod noise/point cloud mixture of the target classes. For example, figure 1 & 2 represent sample for vegetation and building selected respectively, they were observed from different perspective to ensure possible mixture. Afterwards, various samples for each class are merged.  

<img src="/images/veg sample.png" alt="Study Area"/>  
Vegetation Sample  
<img src="/images/building sample.png" alt="Study Area" style="height: 100%; width:500px;"/>  
Building Sample   

**Training and Classification**
As a convention in open source software, qCanupo plugin has been implemented in CloudComapre to handle the training and classification of point cloud data, [read more](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016GL072070) about it usage in exiting publication. The training samples for each class is evaluated with different metrics in CANUPO based on linear discriminant and distance to the boundary between the two clusters; the balanced accuracy and the [Fisher Discriminant Ratio (FDR)](https://en.wikipedia.org/wiki/Linear_discriminant_analysis) metric are consider for the evaluation as provided by qCanupo. For the study, a balanced accuracy of 0.95525 and FDR of 4.434 are obtianed setting the scale to *10*.  
<img src="/images/Stats.png" alt="Statistics" style="height: 100%; width:500px;"/>  
Evalution metrics

Result
===
Below is the result of  the binary classification (Vegetation and Building) combined with the Ground point cloud.  
<img src="/images/Result1.png" alt="Statistics" style="height: 100%; width:500px;"/>  
  

<img src="/images/res2.png" alt="Statistics" style="height: 100%; width:90%;"/>  

